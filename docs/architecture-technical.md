# Architecture Technical Reference

> Generated by Document Project workflow on 2026-02-19
>
> For the user-facing architecture guide with diagrams, see [ARCHITECTURE.md](./ARCHITECTURE.md).
> This document provides deeper technical detail for AI-assisted development.

## Executive Summary

This is a multi-file Docker Compose infrastructure project that orchestrates 27+ containers for automated media management on a NAS. The architecture is layered: infrastructure (Traefik, Cloudflared), application (media stack), and optional utilities (monitoring). Services communicate via a shared bridge network with static IPs, with download services isolated behind a VPN gateway (Gluetun) using Docker's `network_mode: service:` for network namespace sharing.

## Architecture Pattern

**Pattern:** Layered Docker Compose with VPN network namespace sharing

The stack uses a multi-file compose architecture where each file represents a deployment layer:

1. **`docker-compose.traefik.yml`** - Creates networks, deploys reverse proxy
2. **`docker-compose.arr-stack.yml`** - All application services (depends on networks from #1)
3. **`docker-compose.cloudflared.yml`** - External access tunnel (optional)
4. **`docker-compose.utilities.yml`** - Monitoring and tools (optional)

### VPN Network Namespace Model

Download services share Gluetun's network namespace via `network_mode: service:gluetun`. This means:

- They have **no own IP address** on the Docker network
- All their traffic exits through Gluetun's VPN tunnel
- They communicate with each other via `localhost`
- External services reach them via `gluetun` hostname (172.20.0.3)
- Port mappings for these services are defined on the `gluetun` service

**Services sharing Gluetun's namespace:** qBittorrent, SABnzbd, Sonarr, Radarr, Prowlarr, Recyclarr

### macvlan Networking

Traefik, Pi-hole, and Tailscale have dual-network attachment:
- `arr-stack` bridge (for inter-container communication)
- `traefik-lan` macvlan (for physical LAN presence with their own IP + MAC)

This solves the problem of port 80 and DHCP broadcast access, which require a real LAN IP that the NAS host can't share.

**macvlan limitation:** Containers on macvlan cannot reach the Docker host (NAS). The Tailscale service includes a workaround static route:
```
ip route add ${NAS_IP}/32 via 172.20.0.1 dev eth0
```

## Service Dependency Graph

```
                    Pi-hole (DNS)
                        │
                        ▼
                    Gluetun (VPN)
                   ╱    │    ╲
                  ╱     │     ╲
                 ▼      ▼      ▼
            Sonarr   Radarr   Prowlarr
              │        │
              ▼        ▼
          qBittorrent  SABnzbd
              │        │
              ▼        ▼
         ┌────────────────────┐
         │   Media Storage     │
         │  /volume1/Media/    │
         └────────────────────┘
                  │
                  ▼
              Jellyfin (streaming)

          Seerr ──────────► Sonarr/Radarr (via gluetun:port)
          Bazarr ─────────► Sonarr/Radarr (via gluetun:port)
          Recyclarr ──────► Sonarr/Radarr (via localhost)

          TeslaMate ──────► TeslaMate-DB (PostgreSQL)
                    ──────► Mosquitto (MQTT)
          Grafana ────────► TeslaMate-DB

          Immich Server ──► Immich-PG (PostgreSQL + pgvecto.rs)
                        ──► Immich-Redis (Valkey)
          Immich ML ──────► (standalone, called by server)
```

## Service Inter-Communication Matrix

| From | To | Address | Protocol | Notes |
|------|----|---------|----------|-------|
| Sonarr | qBittorrent | `localhost:8085` | HTTP API | Same network namespace |
| Sonarr | SABnzbd | `localhost:8080` | HTTP API | Same network namespace |
| Radarr | qBittorrent | `localhost:8085` | HTTP API | Same network namespace |
| Radarr | SABnzbd | `localhost:8080` | HTTP API | Same network namespace |
| Prowlarr | Sonarr | `localhost:8989` | HTTP API | Same network namespace |
| Prowlarr | Radarr | `localhost:7878` | HTTP API | Same network namespace |
| Prowlarr | FlareSolverr | `172.20.0.10:8191` | HTTP API | Direct IP (outside VPN) |
| Seerr | Sonarr | `gluetun:8989` | HTTP API | Via Gluetun hostname |
| Seerr | Radarr | `gluetun:7878` | HTTP API | Via Gluetun hostname |
| Seerr | Jellyfin | `jellyfin:8096` | HTTP API | Direct container name |
| Bazarr | Sonarr | `gluetun:8989` | HTTP API | Via Gluetun hostname |
| Bazarr | Radarr | `gluetun:7878` | HTTP API | Via Gluetun hostname |
| TeslaMate | TeslaMate-DB | `teslamate-db:5432` | PostgreSQL | Container name |
| TeslaMate | Mosquitto | `mosquitto:1883` | MQTT | Container name |
| Grafana | TeslaMate-DB | `teslamate-db:5432` | PostgreSQL | Container name |
| Immich | Immich-PG | `immich-postgres:5432` | PostgreSQL | Container name |
| Immich | Immich-Redis | `immich-redis:6379` | Redis/Valkey | Container name |
| Gluetun | Pi-hole | `172.20.0.5:53` | DNS | Static IP (DNS_ADDRESS env) |
| Cloudflared | Traefik | `172.20.0.2:80` | HTTP | Tunnel ingress |
| LAN devices | Pi-hole | `PIHOLE_LAN_IP:53` | DNS | macvlan IP |
| LAN devices | Traefik | `TRAEFIK_LAN_IP:80` | HTTP | macvlan IP, routes to service |

## IP Address Allocation

### Bridge Network (arr-stack: 172.20.0.0/24)

| IP | Service | Compose File | Notes |
|----|---------|-------------|-------|
| 172.20.0.1 | Gateway | - | Bridge gateway |
| 172.20.0.2 | Traefik | traefik.yml | + macvlan |
| 172.20.0.3 | Gluetun | arr-stack.yml | VPN gateway + VPN services |
| 172.20.0.4 | Jellyfin | arr-stack.yml | Media server |
| 172.20.0.5 | Pi-hole | arr-stack.yml | DNS/DHCP + macvlan + vpn-net |
| 172.20.0.6 | TeslaMate | arr-stack.yml | Tesla logger |
| 172.20.0.7 | TeslaMate-DB | arr-stack.yml | PostgreSQL |
| 172.20.0.8 | Seerr | arr-stack.yml | Request portal |
| 172.20.0.9 | Bazarr | arr-stack.yml | Subtitles |
| 172.20.0.10 | FlareSolverr | arr-stack.yml | CAPTCHA bypass |
| 172.20.0.11 | Grafana | arr-stack.yml | Tesla dashboards |
| 172.20.0.12 | Cloudflared | cloudflared.yml | Tunnel |
| 172.20.0.13 | Uptime Kuma | utilities.yml | Monitoring |
| 172.20.0.14 | duc | utilities.yml | Disk usage |
| 172.20.0.15 | Beszel | utilities.yml | System metrics |
| 172.20.0.16 | Tailscale | arr-stack.yml | Mesh VPN + macvlan |
| 172.20.0.17 | Mosquitto | arr-stack.yml | MQTT |
| 172.20.0.18 | Immich Server | arr-stack.yml | Photo server |
| 172.20.0.19 | Immich ML | arr-stack.yml | Machine learning |
| 172.20.0.20 | Immich PG | arr-stack.yml | PostgreSQL + pgvecto.rs |
| 172.20.0.21 | Immich Redis | arr-stack.yml | Valkey |
| 172.20.0.22 | Recyclarr | arr-stack.yml | Quality sync |
| 172.20.0.23 | DIUN | utilities.yml | Image update notifier |

### VPN Network (vpn-net: 10.8.1.0/24)

| IP | Service |
|----|---------|
| 10.8.1.200 | Pi-hole |
| (dynamic) | Gluetun |

### macvlan Network (traefik-lan)

| IP (from .env) | Service | Purpose |
|-----------------|---------|---------|
| `TRAEFIK_LAN_IP` | Traefik | Port 80 on LAN |
| `PIHOLE_LAN_IP` | Pi-hole | DNS + DHCP on LAN |
| `TAILSCALE_LAN_IP` | Tailscale | Subnet routing |

## Volume Architecture

### Named Volumes (Docker-managed)

| Volume | Service | Backed Up | Size |
|--------|---------|-----------|------|
| gluetun-config | Gluetun | Yes | ~7MB |
| qbittorrent-config | qBittorrent | Yes | ~9MB |
| sabnzbd-config | SABnzbd | Yes | - |
| sonarr-config | Sonarr | No | ~43MB |
| radarr-config | Radarr | No | ~110MB |
| prowlarr-config | Prowlarr | Yes | ~22MB |
| jellyfin-config | Jellyfin | No | ~407MB |
| jellyfin-cache | Jellyfin | No | ~43MB |
| seerr-config | Seerr | Yes | ~5MB |
| bazarr-config | Bazarr | Yes | ~2MB |
| pihole-etc-pihole | Pi-hole | No | ~138MB |
| pihole-etc-dnsmasq | Pi-hole | Yes | ~4KB |
| tailscale-state | Tailscale | Yes | - |
| teslamate-db | TeslaMate DB | No | - |
| teslamate-grafana-data | Grafana | No | - |
| teslamate-mosquitto-conf | Mosquitto | No | - |
| teslamate-mosquitto-data | Mosquitto | No | - |
| immich-postgres | Immich DB | No | - |
| immich-redis | Immich Redis | No | - |
| immich-ml-cache | Immich ML | No | - |
| recyclarr-config | Recyclarr | Yes | - |

### Bind Mounts (from repo)

| Host Path | Container Path | Service |
|-----------|---------------|---------|
| `./traefik/traefik.yml` | `/traefik.yml` | Traefik |
| `./traefik/dynamic` | `/dynamic` | Traefik |
| `./pihole/02-local-dns.conf` | `/etc/dnsmasq.d/02-local-dns.conf` | Pi-hole |
| `./recyclarr/recyclarr.yml` | `/config/recyclarr.yml` | Recyclarr |
| `./recyclarr/secrets.yml` | `/config/secrets.yml` | Recyclarr |
| `./mosquitto/mosquitto.conf` | `/mosquitto/config/mosquitto.conf` | Mosquitto |
| `./cloudflared/` | `/home/nonroot/.cloudflared` | Cloudflared |
| `/var/run/docker.sock` | `/var/run/docker.sock` | Traefik, Uptime Kuma, Deunhealth, Beszel-agent, DIUN |

### Media Mounts

| Host Path | Container Path | Service | Access |
|-----------|---------------|---------|--------|
| `${MEDIA_ROOT}/downloads` | `/downloads` | qBittorrent, SABnzbd, Sonarr, Radarr | Read/Write |
| `${MEDIA_ROOT}/tv` | `/tv` | Sonarr, Bazarr | Read/Write |
| `${MEDIA_ROOT}/tv` | `/media/tv` | Jellyfin | Read-only |
| `${MEDIA_ROOT}/movies` | `/movies` | Radarr, Bazarr | Read/Write |
| `${MEDIA_ROOT}/movies` | `/media/movies` | Jellyfin | Read-only |
| `/volume1/immich/upload` | `/usr/src/app/upload` | Immich | Read/Write |

## Health Check Strategy

Every service has a health check with appropriate intervals:

| Service | Check Method | Interval | Start Period |
|---------|-------------|----------|-------------|
| Gluetun | Built-in healthcheck binary | 1m | 30s |
| qBittorrent | curl localhost + wget google.com | 2m | 60s |
| SABnzbd | curl localhost + wget google.com | 3m | 60s |
| Sonarr/Radarr | curl localhost + wget google.com | 2m | 60s |
| Prowlarr | curl localhost + wget google.com | 2m | 60s |
| Jellyfin | curl /health endpoint | 1m | 30s |
| Pi-hole | dig @127.0.0.1 google.com | 30s | 30s |
| Seerr | wget /api/v1/status | 2m | - |
| Bazarr | curl localhost:6767 | 3m | - |
| FlareSolverr | POST /v1 with solve request | 10m | 2m |
| Tailscale | tailscale status --json | 1m | 30s |
| Traefik | Built-in ping | 30s | 60s |
| Cloudflared | tunnel info command | 30s | 30s |
| TeslaMate | TCP check port 4000 | 1m | 30s |
| Immich Server | curl /api/server/ping | 1m | 30s |
| Immich ML | Python urllib /ping | 1m | 2m |

**VPN health pattern:** Download services check both local UI (`curl localhost`) AND internet connectivity (`wget google.com`). This detects VPN-down scenarios where the local process runs but has no internet.

## Restart and Recovery

### Deunhealth Auto-Recovery

Services labeled `deunhealth.restart.on.unhealthy=true` are automatically restarted by the Deunhealth container when they become unhealthy. This handles VPN reconnection scenarios where Gluetun recovers but dependent services need a restart.

**Labeled services:** qBittorrent, SABnzbd, Sonarr, Radarr, Prowlarr, FlareSolverr, Cloudflared

### Startup Dependencies

```yaml
Pi-hole (healthy) → Gluetun (healthy) → [qBittorrent, SABnzbd, Sonarr, Radarr, Prowlarr, Recyclarr]
Gluetun (healthy) → [Seerr, Bazarr]
TeslaMate-DB (healthy) + Mosquitto (started) → TeslaMate
Immich-PG (healthy) + Immich-Redis (healthy) → Immich Server
```

### Critical Restart Rule

**Never use `docker compose down`** on the arr-stack. Pi-hole provides DNS and DHCP for the entire LAN. Stopping it kills network connectivity before you can run `up -d`.

**Always use:** `docker compose -f docker-compose.arr-stack.yml up -d --force-recreate`

When recreating Gluetun, always recreate ALL dependent services. Docker stores the actual container ID at creation time; if Gluetun is recreated but dependents aren't, they point to a stale network namespace.

## Security Architecture

### Secrets Management

- All credentials stored in `.env` (gitignored)
- Compose files use `${VAR_NAME}` references
- Pre-commit hook detects leaked secrets (API keys, bcrypt hashes, private keys)
- `.example` files use placeholders (`yourdomain.com`, `your_password_here`)

### Network Isolation

- Download traffic encrypted via VPN (Gluetun/WireGuard)
- Cloudflare Tunnel for external access (no open router ports)
- Admin UIs (Sonarr, Radarr, etc.) are LAN-only by default
- Pi-hole macvlan for DHCP isolation
- Containers run with `security_opt: no-new-privileges` (Traefik)

### Container Privileges

| Service | Capability | Reason |
|---------|-----------|--------|
| Gluetun | NET_ADMIN | VPN tunnel management |
| Pi-hole | NET_ADMIN | DHCP broadcasting |
| Tailscale | NET_ADMIN, NET_RAW, SYS_MODULE | Subnet routing, ip_forward |

## Testing Strategy

### BATS Test Suite

Located in `tests/` with 6 test files:

| Test File | Validates |
|-----------|----------|
| `compose-validation.bats` | Docker Compose file syntax and structure |
| `env-vars.bats` | Environment variable coverage |
| `port-conflicts.bats` | No duplicate port mappings |
| `pre-commit-checks.bats` | Pre-commit hook functionality |
| `security.bats` | No leaked secrets in tracked files |

### Pre-commit Validation (11 Checks)

| # | Check | Severity | Description |
|---|-------|----------|-------------|
| 1 | Secrets | BLOCK | API keys, passwords, bcrypt, private keys |
| 2 | Env vars | BLOCK | All `${VAR}` documented in `.env.example` |
| 3 | YAML syntax | BLOCK | Valid YAML (PyYAML or tab detection) |
| 4 | Port/IP conflicts | BLOCK | No duplicate ports or static IPs |
| 5 | Compose drift | WARN | Jellyfin/Plex variant consistency |
| 6 | Hardcoded domain | BLOCK/WARN | Domain/hostname leak detection |
| 7 | NAS .env backup | WARN | Remote .env sync check (SSH) |
| 8 | Uptime monitors | WARN | Uptime Kuma monitor sync (SSH) |
| 9 | DNS duplicates | WARN | No duplicate `.lan` domains |
| 10 | Domain accessibility | WARN | Domain resolution check |
| 11 | Image versions | WARN | Docker image staleness (30s timeout) |

## Deployment Architecture

### Deployment Flow

```
Local machine (development)
    │
    ├── git commit (pre-commit hooks validate)
    ├── git push
    │
    ▼
GitHub repository
    │
    ▼
NAS (production)
    ├── git pull (in /volume2/docker/arr-stack/)
    └── docker compose up -d --force-recreate
```

### Deployment Order

1. `docker compose -f docker-compose.traefik.yml up -d` (creates networks)
2. `docker compose -f docker-compose.cloudflared.yml up -d` (tunnel)
3. `docker compose -f docker-compose.arr-stack.yml up -d` (main stack)
4. `docker compose -f docker-compose.utilities.yml up -d` (optional)

### Backup Automation

- Daily cron at 6am: `backup-volumes.sh --tar /mnt/arr-backup`
- Backs up essential configs (~13MB compressed)
- Keeps 7 days on USB drive with rotation
- EXIT trap ensures services stay running on failure
- Home Assistant webhook notification on failure
